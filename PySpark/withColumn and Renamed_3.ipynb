{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RTrUYP2WMtNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a5fd51-80fd-41f7-b709-494b79af7fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=6b124bc4532c49aa8b77a7235c5d762f6dd0bf3090a7eb9c53e95ed6e49efdf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "0Gs2-xOQWBBr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark= SparkSession.builder.appName(\"test\").getOrCreate()"
      ],
      "metadata": {
        "id": "ZV_cpUz9Wmze"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =[(1,'Maheer','3000'),(2,'Wafa','4000')]\n",
        "columns= [\"id\",\"name\",'salary']\n",
        "df= spark.createDataFrame(data=data,schema= columns)"
      ],
      "metadata": {
        "id": "S0cvWnU4XL9i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohmwiKpDXhWl",
        "outputId": "b8cfcf08-c696-4a84-ff54-8ce866a51163"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+\n",
            "| id|  name|salary|\n",
            "+---+------+------+\n",
            "|  1|Maheer|  3000|\n",
            "|  2|  Wafa|  4000|\n",
            "+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2iLlNxQXkCn",
        "outputId": "a78009f4-ed35-42f6-e4f1-714002918df1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uf7kPD20Xoau",
        "outputId": "2ffafb92-9e68-40bc-f0d8-6cf6781fc428"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[id: bigint, name: string, salary: string]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(df.withColumn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqgk8LiTX2K3",
        "outputId": "247794a4-129f-4d65-c384-65ebf670f1ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method withColumn in module pyspark.sql.dataframe:\n",
            "\n",
            "withColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
            "    Returns a new :class:`DataFrame` by adding a column or replacing the\n",
            "    existing column that has the same name.\n",
            "    \n",
            "    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n",
            "    a column from some other :class:`DataFrame` will raise an error.\n",
            "    \n",
            "    .. versionadded:: 1.3.0\n",
            "    \n",
            "    .. versionchanged:: 3.4.0\n",
            "        Supports Spark Connect.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    colName : str\n",
            "        string, name of the new column.\n",
            "    col : :class:`Column`\n",
            "        a :class:`Column` expression for the new column.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    :class:`DataFrame`\n",
            "        DataFrame with new or replaced column.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    This method introduces a projection internally. Therefore, calling it multiple\n",
            "    times, for instance, via loops in order to add multiple columns can generate big\n",
            "    plans which can cause performance issues and even `StackOverflowException`.\n",
            "    To avoid this, use :func:`select` with multiple columns at once.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
            "    >>> df.withColumn('age2', df.age + 2).show()\n",
            "    +---+-----+----+\n",
            "    |age| name|age2|\n",
            "    +---+-----+----+\n",
            "    |  2|Alice|   4|\n",
            "    |  5|  Bob|   7|\n",
            "    +---+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "lcNWap0EYPlR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.withColumn(colName='salary',col= col('salary').cast(\"Integer\"))"
      ],
      "metadata": {
        "id": "WxLrgj9FbAQj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HdpvmN8bZxg",
        "outputId": "e1dbf1f6-c0ea-4d64-8820-f94babafcc44"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+\n",
            "| id|  name|salary|\n",
            "+---+------+------+\n",
            "|  1|Maheer|  3000|\n",
            "|  2|  Wafa|  4000|\n",
            "+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Ec0H7pboA5",
        "outputId": "0492cd2b-894f-42d0-a3e1-176c9f4a696f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('id', 'bigint'), ('name', 'string'), ('salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2= df1.withColumn('salary', col(\"salary\")*2)"
      ],
      "metadata": {
        "id": "ua5hrp8fbsn9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhCAxVpFb5x_",
        "outputId": "4c39d50b-bcb9-4fff-ff5c-0d26bb9a7d19"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+\n",
            "| id|  name|salary|\n",
            "+---+------+------+\n",
            "|  1|Maheer|  6000|\n",
            "|  2|  Wafa|  8000|\n",
            "+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df2.withColumn('country',lit('india'))\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGBjIwBpcDps",
        "outputId": "2935d129-a871-4125-ecc0-b704ac1e90f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+-------+\n",
            "| id|  name|salary|country|\n",
            "+---+------+------+-------+\n",
            "|  1|Maheer|  6000|  india|\n",
            "|  2|  Wafa|  8000|  india|\n",
            "+---+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4=df3.withColumn('CopiedsSal',col(\"salary\"))\n",
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGzgX966cbmM",
        "outputId": "e05e37c4-4bc6-46f8-cd74-396eb7ed7ee2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+-------+----------+\n",
            "| id|  name|salary|country|CopiedsSal|\n",
            "+---+------+------+-------+----------+\n",
            "|  1|Maheer|  6000|  india|      6000|\n",
            "|  2|  Wafa|  8000|  india|      8000|\n",
            "+---+------+------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmZ401yvc5o4",
        "outputId": "550b57e0-6792-4817-a267-29f212a871df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'name', 'salary']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(df.withColumnRenamed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Z_CBYMdYFu",
        "outputId": "2f6c14d2-b053-4698-da61-75d91c983d47"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method withColumnRenamed in module pyspark.sql.dataframe:\n",
            "\n",
            "withColumnRenamed(existing: str, new: str) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
            "    Returns a new :class:`DataFrame` by renaming an existing column.\n",
            "    This is a no-op if the schema doesn't contain the given column name.\n",
            "    \n",
            "    .. versionadded:: 1.3.0\n",
            "    \n",
            "    .. versionchanged:: 3.4.0\n",
            "        Supports Spark Connect.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    existing : str\n",
            "        string, name of the existing column to rename.\n",
            "    new : str\n",
            "        string, new name of the column.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    :class:`DataFrame`\n",
            "        DataFrame with renamed column.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
            "    >>> df.withColumnRenamed('age', 'age2').show()\n",
            "    +----+-----+\n",
            "    |age2| name|\n",
            "    +----+-----+\n",
            "    |   2|Alice|\n",
            "    |   5|  Bob|\n",
            "    +----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCabMrMF6EN4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}